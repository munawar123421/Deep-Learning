{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3047725,"sourceType":"datasetVersion","datasetId":1866301}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T07:42:51.923443Z","iopub.execute_input":"2025-09-02T07:42:51.923762Z","iopub.status.idle":"2025-09-02T07:42:52.313982Z","shell.execute_reply.started":"2025-09-02T07:42:51.923737Z","shell.execute_reply":"2025-09-02T07:42:52.312905Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wine-quality-dataset/WineQT.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\n\n# 1. Load dataset\nfile_path = \"/kaggle/input/wine-quality-dataset/WineQT.csv\"\ndata = pd.read_csv(file_path)\n\n# Features (X) and target (y)\nX = data.drop(\"quality\", axis=1).values\ny = data[\"quality\"].values\n\n# Normalize features\nX = (X - X.mean(axis=0)) / X.std(axis=0)\n\n# Convert to tensors\nX = tf.constant(X, dtype=tf.float32)\ny = tf.constant(y, dtype=tf.float32)\n\n# Reshape y to column vector\ny = tf.reshape(y, (-1, 1))\n\n# 2. Initialize weights and bias (random initialization)\nn_features = X.shape[1]\nW = tf.Variable(tf.random.normal((n_features, 1)))\nb = tf.Variable(tf.random.normal((1,)))\n\nprint(\"Initial Weights (first 5):\", W.numpy().flatten()[:5])\nprint(\"Initial Bias:\", b.numpy())\n\n# Learning rate\nlr = 0.1\n\n# 3. Training loop for 10 epochs\nfor epoch in range(1, 11):\n    with tf.GradientTape() as tape:\n        # Forward pass: y_pred = XW + b\n        y_pred = tf.matmul(X, W) + b\n\n        # Loss function: Mean Squared Error (MSE)\n        loss = tf.reduce_mean(tf.square(y_pred - y))\n\n    # 4. Backward pass: compute gradients\n    dW, db = tape.gradient(loss, [W, b])\n\n    # 5. Update weights (Gradient Descent)\n    W.assign_sub(lr * dW)\n    b.assign_sub(lr * db)\n\n    # Print progress\n    print(f\"Epoch {epoch}: Loss = {loss.numpy():.4f}\")\n    print(f\"  Weights[0:5] = {W.numpy().flatten()[:5]}\")\n    print(f\"  Bias = {b.numpy()}\\n\")\n\n# 6. Final predictions after training\ny_pred_final = tf.matmul(X, W) + b\n\nprint(\"Final Trained Weights (first 5):\", W.numpy().flatten()[:5])\nprint(\"Final Bias:\", b.numpy())\nprint(\"\\nSample Predictions vs Actual:\")\nfor i in range(5):\n    pred_val = float(y_pred_final[i].numpy())  # convert to scalar\n    actual_val = float(y[i].numpy())           # convert to scalar\n    print(f\"  Predicted: {pred_val:.2f}, Actual: {actual_val:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T07:58:21.949470Z","iopub.execute_input":"2025-09-02T07:58:21.949869Z","iopub.status.idle":"2025-09-02T07:58:22.034706Z","shell.execute_reply.started":"2025-09-02T07:58:21.949842Z","shell.execute_reply":"2025-09-02T07:58:22.033201Z"}},"outputs":[{"name":"stdout","text":"Initial Weights (first 5): [ 1.1585038 -0.7767726  1.9194883  1.4202784  0.6558985]\nInitial Bias: [-0.5341805]\nEpoch 1: Loss = 59.2506\n  Weights[0:5] = [ 0.56416947 -0.45689717  1.2126341   0.9126259   0.35986862]\n  Bias = [0.70406413]\n\nEpoch 2: Loss = 30.1777\n  Weights[0:5] = [ 0.377819   -0.32693738  0.9113035   0.6342833   0.25681847]\n  Bias = [1.69466]\n\nEpoch 3: Loss = 18.5321\n  Weights[0:5] = [ 0.32746205 -0.26737323  0.7576661   0.46328038  0.21782504]\n  Bias = [2.4871366]\n\nEpoch 4: Loss = 12.0057\n  Weights[0:5] = [ 0.32057154 -0.23588799  0.66110384  0.34944683  0.19873032]\n  Bias = [3.1211178]\n\nEpoch 5: Loss = 7.9637\n  Weights[0:5] = [ 0.32622516 -0.21701336  0.58922696  0.2698867   0.18483603]\n  Bias = [3.6283028]\n\nEpoch 6: Loss = 5.3911\n  Weights[0:5] = [ 0.3344463  -0.2047142   0.5300273   0.21277289  0.17161132]\n  Bias = [4.034051]\n\nEpoch 7: Loss = 3.7355\n  Weights[0:5] = [ 0.34225422 -0.19635738  0.47871807  0.17122409  0.15796074]\n  Bias = [4.3586493]\n\nEpoch 8: Loss = 2.6614\n  Weights[0:5] = [ 0.3489258  -0.19060886  0.4331406   0.1408446   0.14388156]\n  Bias = [4.618328]\n\nEpoch 9: Loss = 1.9591\n  Weights[0:5] = [ 0.35441592 -0.1866853   0.3921455   0.11864321  0.12965867]\n  Bias = [4.8260713]\n\nEpoch 10: Loss = 1.4958\n  Weights[0:5] = [ 0.35884944 -0.18407442  0.35501036  0.10250202  0.11559845]\n  Bias = [4.9922657]\n\nFinal Trained Weights (first 5): [ 0.35884944 -0.18407442  0.35501036  0.10250202  0.11559845]\nFinal Bias: [4.9922657]\n\nSample Predictions vs Actual:\n  Predicted: 4.45, Actual: 5.00\n  Predicted: 3.31, Actual: 5.00\n  Predicted: 3.93, Actual: 5.00\n  Predicted: 5.48, Actual: 6.00\n  Predicted: 4.45, Actual: 5.00\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/2754772431.py:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  pred_val = float(y_pred_final[i].numpy())  # convert to scalar\n/tmp/ipykernel_36/2754772431.py:62: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n  actual_val = float(y[i].numpy())           # convert to scalar\n","output_type":"stream"}],"execution_count":7}]}