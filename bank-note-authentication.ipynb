{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1738824,"sourceType":"datasetVersion","datasetId":1032090}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T08:56:57.512636Z","iopub.execute_input":"2025-09-02T08:56:57.512915Z","iopub.status.idle":"2025-09-02T08:56:58.029467Z","shell.execute_reply.started":"2025-09-02T08:56:57.512888Z","shell.execute_reply":"2025-09-02T08:56:58.028632Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/banknote-authenticationcsv/BankNote_Authentication.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nfrom sklearn.metrics import accuracy_score\n\n# 1. Load dataset\nfile_path = \"/kaggle/input/banknote-authenticationcsv/BankNote_Authentication.csv\"\ndata = pd.read_csv(file_path)\n\n# Features and target\nX = data.drop('class', axis=1).values\ny = data['class'].values\n\n# Handle class imbalance by upsampling minority class (manual SMOTE alternative)\ndf = pd.DataFrame(data)\nmajority = df[df['class']==0]\nminority = df[df['class']==1]\nminority_upsampled = resample(minority,\n                              replace=True,\n                              n_samples=len(majority),\n                              random_state=42)\ndf_balanced = pd.concat([majority, minority_upsampled])\n\nX_res = df_balanced.drop('class', axis=1).values\ny_res = df_balanced['class'].values\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n\n# Standardize features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Convert to tensors\ntf_X_train = tf.constant(X_train, dtype=tf.float32)\ntf_y_train = tf.constant(y_train.reshape(-1,1), dtype=tf.float32)\ntf_X_test = tf.constant(X_test, dtype=tf.float32)\ntf_y_test = tf.constant(y_test.reshape(-1,1), dtype=tf.float32)\n\n# 2. Build a simple ANN\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n    tf.keras.layers.Dense(8, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# 3. Compile model with SGD optimizer and binary cross-entropy\nmodel.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# 4. Train model\nhistory = model.fit(tf_X_train, tf_y_train, epochs=10, batch_size=32, verbose=1)\n\n# 5. Predictions on test set\ny_pred_prob = model.predict(tf_X_test)\ny_pred_class = (y_pred_prob > 0.5).astype(int)\n\n# 6. Evaluate accuracy\nacc = accuracy_score(y_test, y_pred_class)\nprint(f\"\\nTest Accuracy after balancing and ANN training: {acc:.4f}\")\n\n# 7. Show some sample predictions\nprint(\"\\nSample Predictions vs Actual:\")\nfor i in range(5):\n    print(f\"  Predicted: {y_pred_class[i][0]}, Actual: {y_test[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T09:46:09.971624Z","iopub.execute_input":"2025-09-02T09:46:09.972501Z","iopub.status.idle":"2025-09-02T09:46:12.253308Z","shell.execute_reply.started":"2025-09-02T09:46:09.972472Z","shell.execute_reply":"2025-09-02T09:46:12.252440Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6409 - loss: 0.6028 \nEpoch 2/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.3650\nEpoch 3/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9800 - loss: 0.2177\nEpoch 4/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.1376\nEpoch 5/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0917\nEpoch 6/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.0655\nEpoch 7/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0475\nEpoch 8/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0314\nEpoch 9/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0294\nEpoch 10/10\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0263\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n\nTest Accuracy after balancing and ANN training: 0.9902\n\nSample Predictions vs Actual:\n  Predicted: 1, Actual: 1\n  Predicted: 0, Actual: 0\n  Predicted: 1, Actual: 1\n  Predicted: 1, Actual: 1\n  Predicted: 1, Actual: 1\n","output_type":"stream"}],"execution_count":4}]}